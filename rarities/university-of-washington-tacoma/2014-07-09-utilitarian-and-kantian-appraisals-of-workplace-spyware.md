# Utilitarian and Kantian Appraisals of Workplace Spyware

*Summer 2014 was a pretty big one in terms of my job history. I was a teacher for the Math, Science, Learning Program at the University of Washington, Tacoma. It was fun. I wouldn't say I failed* entirely, *but I failed pretty hard as a teacher. I don't think I'll ever do that again. But, what can we say? I was 19 and they took a chance on me and it didn't pan out super great. My coworkers and the kids were lovely, though.*

*While I was doing that, I was also taking a night class at the university. "TCSS 325: Computer Ethics" with Lori Alward. A friend named Tyson Barber was also in that class. It was pretty chill, as summer classes tend to be. We met a few times a week and talked about really basic frameworks of ethical thought in terms of software. It was an edifying and encriching experience, to the extent that I could be edified and enriched on ethics while still a Fox News thrawl.*

*Ms. Alward was a very nice teacher. Wicked smart and great at explaining these kinds of topics in ways that were engaging to kids pretending to be adults ready to enter the workforce when that workforce is stereotypically anti-intellectual and habitually unethical. Of course, Tyson was older, so I don't know what he thought about the class. I remember I said something really stupid about how developers should be paid or treated or something and he came back with some real-world stuff that was right and was probably closer to what I think now.I remember her story about being stopped at the airport (a bunch of times?) because TSA assumed she was a Muslim based on her last name. The image in my mind when someone talks about utility sponge (or whatever it's called) is the one I had in her class. She described someone who maximized their personal utility by floating on their personal pool all day and never impacting another person negatively by doing so.*

*Another thing that I remember of Ms. Alward is going up to her after class to ask her something about an essay we had just read, "Feminist Transformations of Moral Theory" by Virginia Heald. I don't remember exactly what the problem I had with the essay was, but (barely skimming it in the textbook I still have with notes I wrote then) it probably had something to do with her saying that reason is a genered concept or her thoughts on the family. I would not have identified as a feminist then, even if, although skeptical of feminist means, I agreed with the broad strokes idea that women must be equal to men. It doesn't matter exactly what the specific issue was, though. Basically, I didn't relate to the thrust of one of her arguments even though I guess I was expecting to because it was a "feminist" text. I wanted Ms. Alward to clear up my confusion. And she said something to the effect that it was OK to not find the argument within it compelling. We're all out here trying to figure out what life means and nobody has definitive answers that will speak to everybody else. Perhaps this is obvious, and I'm sure I would have naively parroted the same idea with the mind of a silly teenager (I was 19; I turned 20 that summer). But I don't think it really hit me in a practical and visceral way until then. In hindsight, I guess this is part of the reason that I care less about what an writer is trying to argue than my own thoughts on the subject prompted by what they have created. I don't have to relate to what they say, necessarily, but I'm pretty sure I'll relate to what I think. That's my work of audience.*

*This was the first essay for the class. It was composed with a formal essay-writing process, to the point that there is a big note on the assignment sheet saying* ***"Essays without a thesis statement will receive a grade no higher than a 2."*** *(out of 4). It also says that we may cite exclusively from our textbook, if we so wish. It seems that I did.*

*We had three topics to choose from and were told to "Analyze one of the following moral questions using both Kant's categorical imperative and Mill's principle of utility.... After analyzing the problem using both a Kantian and a utilitarian framework, say which moral approach you think is better, and why." The first topic asks if it would be morally correct for a US government software engineer to programs with spyware that would be distributed in other countries, including US allies. The second topic is the same scenario the first, but you work for a private company and they justify the spyware with "market research." The company has a history of turning over information to the US government. The third topic asks if it is morally right for a company to extensively monitor its employees in real time. It seems I was most interested in the second and third topics, based on the notes. I ultimately chose the second.*

*I have two mind maps and a very rough draft made during the writing process. I must have considered the first topic for a while because it does have its own bubble. The rough draft has notes that were obviously in red within the Word document. "WRITE INTRODUCTION," "KANTIANISM," "~~UTILITARIANISM~~," "COUNTERARGUMENTS," REFUTATION." At the end of a paragraph, "What's more, ??????" In the middle of another "'good will'[DEFINE]." It's so funny to see a glimpse of my old writing process.*

*Measure your expectations, since this is an essay by an undergraduate junior, but I'm hoping this will be fun.* (2020-06-28, before transcription)

*Holy shit, the first sentence of this is a doozy, hahahahahahaha. As I read this, there's just so much that 2014 Mike had yet to learn about the real relationship between employers and employees. Some of this can be attributed to the stiltedness that comes from being told to write about a topic in a certain way, but more of it was from Fox News and indoctrinated bullshit. One thing that sticks out to me is the credulousness with which I treated the company's "market research" justification and my comfort with the assertion that people would not even know they were followed--as if that would make it more utilitarian! I now know that any data collected by a company will tend to be used by that company in any way its management can devise. Laws and morality barely matter when a capitalist wants to extract more labor from their employees for the same amount of money.*

*Just the idea that I wrote a paper arguing directly in favor of employers spying on their employees is so tragically funny to me. The idea that the employer would be* compelled *morally(!) to spy on their employees is so utterly ridiculous. This essay's conclusion is on par with my ["The Yankee Invasion or the Southern Rebellion?"](../rarities/pierce-college-puyallup/2010-11-23-the-yankee-invasion-or-the-southern-rebellion-why-the-united-states-fought-a-civil-war.md). Horrible.*

*I did not fix typos.*

*Ms. Alward had two notes. At my statement that I would not do a formal categorical imperative analysis (i.e., try to make a maxim), she wrote "It would be interesting to ask what the company's maxim is, and whether it can be univeralized. If it can be, then the policy would be morally permissible, on Kant's view." True. Based only on this text, I suspect I just couldn't decide on a maxim to create and argue about. I may not have tried to make one or failed to think of one. Here's a modern suggestion: you must never track your employees like they're machines you own.*

*The other note is my score, which was a 3.9 out of 4. "Excellent work! It would be good to fully develop a counterargument to your view, and show how you can argue against it." Also true. Not sure how I got such a high score, then, though. Maybe she just liked my writing style. Who knows?* (2020-06-28, during transcription)

-----

(2014-07-09)

(All citations are to *Information Ethics: Privacy, Property, and Power*, edited by Adam D. Moore. The essays cited were "Utilitarianism" by John Stuart Mill (pp.47-65) and "The Metaphysics of Morals" by Immanuel Kant (pp. 66-84)

Workers and employers have needs, many of which are shared. For instance, both can have livelihoods that depend upon the subsistence of the company or a desire for a professional atmosphere while working. Other needs are more individual in nature, such as a feeling of belonging within the team or feelings of self-efficacy. The satisfaction of individual needs like those is of interest of the entire group: if all team members have many needs met, they will be more likely to synergize, be happier, and be more productive. It follows that a popular strategy for team membership is to foster this synergy from all levels, with employers and workers working together to please themselves and the other group.

Privacy rights are a potential example of one of these contentious needs. Consider the case of a programmer working for a software firm who is ordered to create monitoring software--in a general term, a form of spyware--that will monitor employees throughout their days. The justification they provide for this is that the monitoring will provide them with market research. This is clearly an effort on the employer's part that compromises the worker's privacy, in the sense that people believe they should be able to regulate what information about themselves is recorded and the worker is going to be compelled to work for the employer under conditions in which data about them is going to be saved.

In the cases where these needs clash, there needs to be a way to discuss the dispute and come to a plan of action. Moral Theory frameworks help with this. Different frameworks may come to differing conclusions, so consulting multiple is advisable. I will show the fundamental difference between two popular frameworks, Utilitarianism and Kantianism, and apply both to this privacy situation. Utilitarianism and Kantianism consider the morality of different actions in fundamentally different ways. I will show that the Utilitarian framework is more effective for analyzing this situation because it provides a solid result while Kantianism does not.

As championed by John Stuart Mill, Utilitarians believe that "actions are right in proportion as they tend to promote happiness, wrong as they tend to produce the reverse of happiness" (47). This happiness, as defined by Mill, is "pleasure, and freedom from pain," and he is careful to neglect putting a limit on what that means for individual people. Utilitarianism is concerned with the "promotion of happiness" for the greatest number of people possible. Furthermore, they believe that the intention or motivations of actors do not truly promote happiness. Instead, it is the consequences of those actions, the effects on the collective, that matter when one judges morality, and this is often done by tabulating the benefits to people and the costs to them.

In the case of spyware, the direct consequence is the collection of market research, as stated by the company. Presumably, gathering data in this way would make the company's leaders happy. The information would be useful while informing future decisions. On the employee's end, the possible effect upon their happiness is not so easily predictable. It depends on two factors: were they informed of the surveillance, and was the information shared outside of the company? If the latter is false, the employees would be unaware, and thereby undisturbed, by the policy. It would neither promote happiness nor produce unhappiness for the employee. Because of the satisfaction of the company leaders, there would be a net increase in happiness and a Utilitarian perspective would compel the creation of the spyware.

Nonetheless, since the company has a track record of sharing information when it is requested by the government, it would be remiss to disregard the potential consequences of a situation in which the information is shared. Let us assume that the employee learns about previous information sharing with an outside entity, lest their ignorance also leave them neither more nor less happy. In the case that the data is shared with an outside entity and the employee did not know they were being monitored, the common reaction would be outrage at the breach of their privacy. In a way, that would be painful to them emotionally. This would certainly outweigh the satisfaction of the company leaders' desire, indicative of a path prohibited by Utilitarianism. On the other hand, an employee informed about both the monitoring and the possibility of sharing would, while not necessarily be ambivalent, would have acknowledged their practical comfort with the policy by continuing to work at the company. Employees hired after the policy implementation would also have to be informed of the monitoring and consent to it in the same way. Workers would not be made overly unhappy by the sharing, yet may not be happy about it, either. The existing happiness of the company leaders would win out in this case, compelling the monitoring.

To summarize, in the case that the information is never shared, the employers should create the spyware. In the case that the information will be shared in the future, the employers should inform the employees about the monitoring policy, avoiding a situation in which they would not be allowed to create the spyware. That is a concrete result.

More perspectives could be analyzed in this situation, though the employee perspective should be most heavily weighted. The opinions of the company's clientele on the monitoring policy could potentially be important, for example. If a client had a strong objection to employee monitoring, there is a possibility that the company's actions may upset them and affect the business relationship. However, this then becomes a marginal matter, depending on the number of clients that take issue and the size of the client pool. Comparing the offended number to the entire population, if many are offended, the company may meet then threats of retaliation with more attention. If comparatively few clients object, then the company could accept their own free decision without a fight, up to and including the client cutting ties with the company. The company's meditations on how to handle client reactions may be worthy of its own discussion, and that can happen with Utilitarian arguments. Consequences of actions, deliberate and incidental, can have far-reaching effects, and the number of perspectives and situations that could be relevant can increase quickly. This discussion needs to consider its other moral framework now, however.

The philosopher Immanuel Kant believed that the motivation behind an action determined its morality. He conceived of a "good will" that was necessary for doing morally truly right things. That's not to say that there are no other good things in people's character aside from good wills, but these have "no intrinsic unconditional value" (66). Such things--including happiness and intelligence--"always presuppose a good will," but it is possible to abuse them for immoral purposes when a good will is not present (66). A good will exists when a person chooses intentionally to use a good thing to enact a good end. The consequences have no importance when someone intends to do the right thing.

Kantianism would examine only the intent of the company leaders, see no good will in the intention of gathering market research, and disregard the act as without moral worth, meaning that they followed a proper duty with a good will. The conclusion would be that monitoring the employees would be done for pragmatic reasons alone, which is indicative of a decision made outside of a moral context to a Kantian. Such situations are not inherently immoral in the Kantian perspective, especially if there were good attributes involved like honesty or the preservation of life. What lacking moral worth means is that the action was done because there was no conscious decision to do a moral thing, so the actor's morals were not questioned. In other words, monitoring the employees would be a voluntary act on the part of the company, which is self-evident.

It is true that good will analysis is not the only aspect of Kantianism, and some may say that not delving into the situation with the categorical imperative formally is not being fair to Kant's beliefs, because that concept was so important to him. The categorical imperative extends the concept of duty to following universal laws of conduct. When people take action, they should create a statement, called a maxim, about why they are doing it, phrased as a compulsion. A person should always "act as if the maxim of thy action were to become thy will a universal law of nature" that apples for everyone (78). In the spyware case, it needs to be determined if the goal of collecting market research would be sufficient to make the use of spyware necessary. While it is true that such a practice taken out by every company would be overkill, generalizing that as a universal law presents no contradiction. If all companies adopted a monitoring policy, working life would not be any more difficult or impossible. Employees would be encouraged to work as if the monitors have always been there, in fact. Categorical imperative examination does not reveal new insight in this case.

What makes the Utilitarian model more effective for this analysis is that it forces a person to think about the employees' perspective and confront potential concerns. This allows extrapolation and looking at various eventualities. It acknowledges the different paths this situation can take and not only concludes what should be done; it provides insight into *how* the policy should be implemented.
